{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt\nfrom keras.layers import Embedding, Lambda, Dense, Input, concatenate, dot, multiply,Flatten\nfrom keras.models import Model\nimport keras.backend as K\n\nnp.random.seed(555)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T15:03:21.57514Z","iopub.execute_input":"2022-07-03T15:03:21.576093Z","iopub.status.idle":"2022-07-03T15:03:32.109688Z","shell.execute_reply.started":"2022-07-03T15:03:21.575977Z","shell.execute_reply":"2022-07-03T15:03:32.108557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **数据处理**\n##### 数据集来源为Movielens-1M\n##### 从movies.dat获取电影属性，从ratings.dat获取评分数据，从users.dat获取用户属性\n##### 选择属性“gender”,“age”,\"occupation\",\"year\"作为输入\n##### 对获得的数据划分训练集和测试集，其中训练集占比为0.8，之后进行训练得到结果","metadata":{}},{"cell_type":"code","source":" def get_users_attr(df_users):\n    df_users = pd.read_csv(users_path,sep=\"::\",names=['uid','gender','age','occupation','zipcode'],encoding='utf-8')\n    user_ids=set(df_users['uid'].values)\n    df_users = df_users.drop(['zipcode'],axis=1)\n    for i in range(len(df_users)):\n        if df_users.loc[i,'gender'] == 'F':\n            df_users.loc[i,'gender'] = 1\n        else:\n            df_users.loc[i,'gender'] = 0\n    return df_users,user_ids","metadata":{"execution":{"iopub.status.busy":"2022-07-03T15:03:32.111978Z","iopub.execute_input":"2022-07-03T15:03:32.112848Z","iopub.status.idle":"2022-07-03T15:03:32.121981Z","shell.execute_reply.started":"2022-07-03T15:03:32.112801Z","shell.execute_reply":"2022-07-03T15:03:32.120796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_movies_attr(df_movies):\n    year=df_movies['title'].values\n    for i in range(len(year)):\n        year[i]=year[i].split('(')[-1].split(')')[0]\n    df_movies['year']=year\n    genres_list = set()\n    for sstr in df_movies['genres'].str.split('|'):\n        genres_list = set().union(sstr, genres_list)\n    genres_list = list(genres_list)\n    #genres_dict = dict(zip(genres_list,np.zeros(len(genres_list)) ))\n    #for sstr in df_movies['genres'].str.split('|'):\n    #    for s in sstr:\n    #        genres_dict[s]+=1\n    #rank=sorted(genres_dict.items(),key=lambda kv:kv[1],reverse=True)\n    #for i in range(5):\n    #    genres=rank[i][0]\n    for genres in genres_list:\n        df_movies[genres] = df_movies['genres'].str.contains(genres).apply(lambda x:1 if x else 0)\n    item_ids=set(df_movies['iid'].values)\n    df_movies = df_movies.drop(['title','genres'],axis=1)\n    return df_movies,item_ids","metadata":{"execution":{"iopub.status.busy":"2022-07-03T15:03:32.123799Z","iopub.execute_input":"2022-07-03T15:03:32.124862Z","iopub.status.idle":"2022-07-03T15:03:32.139762Z","shell.execute_reply.started":"2022-07-03T15:03:32.124813Z","shell.execute_reply":"2022-07-03T15:03:32.138937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dict(data):\n    k_ids = set(data)\n    n = len(k_ids)\n    k_dict = dict(zip(k_ids, range(n)))\n    return k_dict,n","metadata":{"execution":{"iopub.status.busy":"2022-07-03T15:03:32.142617Z","iopub.execute_input":"2022-07-03T15:03:32.143456Z","iopub.status.idle":"2022-07-03T15:03:32.151006Z","shell.execute_reply.started":"2022-07-03T15:03:32.143418Z","shell.execute_reply":"2022-07-03T15:03:32.150259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataProcess:\n    def __init__(self, ratings_path, users_path, movies_path, alpha=0.8):\n        print(\"start load data\")\n        df_ratings=pd.read_csv(ratings_path,sep=\"::\",names=['uid', 'iid', 'ratings','time'],encoding='utf-8',engine='python')\n        df_users=pd.read_csv(users_path,sep=\"::\",names=['uid', 'gender', 'age','occupation','zipcode'],encoding='utf-8',engine='python')\n        df_movies=pd.read_csv(movies_path,sep=\"::\",names=['iid', 'title', 'genres'],encoding='ISO-8859-1',engine='python')\n        print(\"start process data\")\n        df_ratings=df_ratings.drop('time',axis=1)\n        df_users,user_ids=get_users_attr(df_users)\n        df_movies,item_ids=get_movies_attr(df_movies)\n    \n        self.n_user=len(user_ids)\n        self.n_item=len(item_ids)\n        u_id2idx = dict(zip(user_ids, range(self.n_user)))\n        i_id2idx = dict(zip(item_ids, range(self.n_item)))\n        \n        df_ratings = df_ratings.assign(uid=[u_id2idx[uid] for uid in df_ratings.uid])\n        df_ratings = df_ratings.assign(iid=[i_id2idx[iid] for iid in df_ratings.iid])\n        df_ratings = df_ratings.loc[df_ratings['uid']<=100]\n        df_ratings = df_ratings.loc[df_ratings['iid']<=500]\n        \n        self.df = pd.merge(pd.merge(df_ratings, df_users, on='uid'), df_movies, on='iid')\n        \n        gender_dict,self.n_gender=get_dict(self.df['gender'])\n        self.df = self.df.assign(gender=[gender_dict[k] for k in self.df['gender']])\n        \n        age_dict,self.n_age=get_dict(self.df['age'])\n        self.df = self.df.assign(age=[age_dict[k] for k in self.df['age']])\n        \n        occupation_dict,self.n_occupation=get_dict(self.df['occupation'])\n        self.df = self.df.assign(occupation=[occupation_dict[k] for k in self.df['occupation']])\n        \n        year_dict,self.n_year=get_dict(self.df['year'])\n        self.df = self.df.assign(year=[year_dict[k] for k in self.df['year']])\n        \n        self.df=pd.DataFrame(self.df,dtype=np.float64)\n        \n        self.X = self.df.drop('ratings', axis=1)\n        self.Y = self.df['ratings'].values","metadata":{"execution":{"iopub.status.busy":"2022-07-03T15:03:32.153315Z","iopub.execute_input":"2022-07-03T15:03:32.154146Z","iopub.status.idle":"2022-07-03T15:03:32.174693Z","shell.execute_reply.started":"2022-07-03T15:03:32.154098Z","shell.execute_reply":"2022-07-03T15:03:32.173841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Nerual_MF_V1**\n##### 借鉴了老师给的Nerual_MF_V1","metadata":{}},{"cell_type":"code","source":"class Nerual_MF_V1:\n    def __init__(self,n_gender,n_age,n_occupation,n_year):\n\n        # Input layer\n        a_in = Input(shape=[1], name='gender')\n        b_in = Input(shape=[1], name='age')\n        c_in = Input(shape=[1], name='occupation')\n        d_in = Input(shape=[1], name='year')\n        \n        # Layer 2\n        embedding_a = Embedding(input_dim=n_gender, output_dim=100, name='embedding_a')(a_in)\n        embedding_b = Embedding(input_dim=n_age, output_dim=100, name='embedding_b')(b_in)\n        embedding_c = Embedding(input_dim=n_occupation, output_dim=100, name='embedding_c')(c_in)\n        embedding_d = Embedding(input_dim=n_year, output_dim=100, name='embedding_d')(d_in)\n\n        # Layer 3\n        SqueezeEmbed = Lambda(lambda x: K.squeeze(x, 1))\n        Sa=SqueezeEmbed(embedding_a)\n        Sb=SqueezeEmbed(embedding_b)\n        Sc=SqueezeEmbed(embedding_c)\n        Sd=SqueezeEmbed(embedding_d)\n        h_mv = concatenate([Sa, Sb])\n        h_usr = concatenate([Sc, Sd])\n\n        # Layer 4\n        h_mv = Dense(units=100, activation='relu')(h_mv)\n        h_usr = Dense(units=100, activation='relu')(h_usr)\n        \n        # Output Layer\n        y = dot([h_mv, h_usr], axes=-1)\n        \n        self.model = Model(inputs=[a_in, b_in, c_in, d_in], outputs=[y], name='WideDeep')","metadata":{"execution":{"iopub.status.busy":"2022-07-03T15:03:32.175769Z","iopub.execute_input":"2022-07-03T15:03:32.176349Z","iopub.status.idle":"2022-07-03T15:03:32.190679Z","shell.execute_reply.started":"2022-07-03T15:03:32.176307Z","shell.execute_reply":"2022-07-03T15:03:32.18976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Nerual_MF_V2**\n##### 借鉴了老师给的Nerual_MF_V2","metadata":{}},{"cell_type":"code","source":"class Nerual_MF_V2:\n    def __init__(self,n_gender,n_age,n_occupation,n_year):\n\n        # Input layer\n        a_in = Input(shape=[1], name='gender')\n        b_in = Input(shape=[1], name='age')\n        c_in = Input(shape=[1], name='occupation')\n        d_in = Input(shape=[1], name='year')\n        \n        # Layer 2\n        embedding_a = Embedding(input_dim=n_gender, output_dim=100, name='embedding_a')(a_in)\n        embedding_b = Embedding(input_dim=n_age, output_dim=100, name='embedding_b')(b_in)\n        embedding_c = Embedding(input_dim=n_occupation, output_dim=100, name='embedding_c')(c_in)\n        embedding_d = Embedding(input_dim=n_year, output_dim=100, name='embedding_d')(d_in)\n\n        # Layer 3\n        SqueezeEmbed = Lambda(lambda x: K.squeeze(x, 1))\n        Sa=SqueezeEmbed(embedding_a)\n        Sb=SqueezeEmbed(embedding_b)\n        Sc=SqueezeEmbed(embedding_c)\n        Sd=SqueezeEmbed(embedding_d)\n        h_mv = concatenate([Sa, Sb])\n        h_usr = concatenate([Sc, Sd])\n\n        # Layer 4\n        h_mv = Dense(units=100, activation='relu')(h_mv)\n        h_usr = Dense(units=100, activation='relu')(h_usr)\n        \n        # Output Layer\n        h_mv_usr = multiply([h_mv, h_usr])\n        h_feat = Dense(units=100, activation='relu')(h_mv_usr)\n        y = Dense(units=1, name='y')(h_feat)\n        \n        self.model = Model(inputs=[a_in, b_in, c_in, d_in], outputs=[y], name='WideDeep')","metadata":{"execution":{"iopub.status.busy":"2022-07-03T15:03:32.191843Z","iopub.execute_input":"2022-07-03T15:03:32.192684Z","iopub.status.idle":"2022-07-03T15:03:32.204868Z","shell.execute_reply.started":"2022-07-03T15:03:32.192644Z","shell.execute_reply":"2022-07-03T15:03:32.203792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **数据导入及二次处理**\n##### 这些本应放在DataProcess里面，但是由于不方便测试而且DataProcess中内容已经很多，所以我把部分数据处理放到后面","metadata":{}},{"cell_type":"code","source":"ratings_path=\"../input/movielens-1m-dataset/ratings.dat\"\nusers_path=\"../input/movielens-1m-dataset/users.dat\"\nmovies_path=\"../input/movielens-1m-dataset/movies.dat\"\ndp = DataProcess(ratings_path,users_path,movies_path)\nX_train,X_test,Y_train,Y_test=train_test_split(dp.X,dp.Y,test_size=0.2,random_state=123)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T15:03:32.206324Z","iopub.execute_input":"2022-07-03T15:03:32.20702Z","iopub.status.idle":"2022-07-03T15:03:43.414081Z","shell.execute_reply.started":"2022-07-03T15:03:32.206974Z","shell.execute_reply":"2022-07-03T15:03:43.413111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X1=X_train['gender'].values\nX2=X_train['age'].values\nX3=X_train['occupation'].values\nX4=X_train['year'].values\nX_train=[X1,X2,X3,X4]\nX1=X_test['gender'].values\nX2=X_test['age'].values\nX3=X_test['occupation'].values\nX4=X_test['year'].values\nX_test=[X1,X2,X3,X4]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T15:03:43.415392Z","iopub.execute_input":"2022-07-03T15:03:43.415913Z","iopub.status.idle":"2022-07-03T15:03:43.42307Z","shell.execute_reply.started":"2022-07-03T15:03:43.415881Z","shell.execute_reply":"2022-07-03T15:03:43.422125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **训练&预测**\n##### 对两个模型结果进行对比，结果显示v2要略优于v1\n##### 使用MAE和RMSE进行评估","metadata":{}},{"cell_type":"code","source":"md = Nerual_MF_V1(dp.n_gender,dp.n_age,dp.n_occupation,dp.n_year)\nmd.model.compile(optimizer='adam', loss='mse')\n# 模型训练\nmd.model.fit(x=X_train, y=Y_train, epochs=20, batch_size=64)\n# 模型预测\nY_predict = md.model.predict(x=X_test)\n\n# MAE,RMSE\nn = len(Y_predict)\ntest_mae = np.sum(np.fabs(Y_predict.flatten() - Y_test)) / n\ntest_rmse = np.sqrt(np.sum((Y_predict.flatten() - Y_test)**2) / n)\nprint('test MAE :{:.4f}|test RMSE :{:.4f}'.format(test_mae,test_rmse))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-03T15:03:43.426225Z","iopub.execute_input":"2022-07-03T15:03:43.426554Z","iopub.status.idle":"2022-07-03T15:03:46.368206Z","shell.execute_reply.started":"2022-07-03T15:03:43.426526Z","shell.execute_reply":"2022-07-03T15:03:46.367323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"md = Nerual_MF_V2(dp.n_gender,dp.n_age,dp.n_occupation,dp.n_year)\nmd.model.compile(optimizer='adam', loss='mse')\n# 模型训练\nmd.model.fit(x=X_train, y=Y_train, epochs=20, batch_size=64)\n# 模型预测\nY_predict = md.model.predict(x=X_test)\n\n# MAE,RMSE\nn = len(Y_predict)\ntest_mae = np.sum(np.fabs(Y_predict.flatten() - Y_test)) / n\ntest_rmse = np.sqrt(np.sum((Y_predict.flatten() - Y_test)**2) / n)\nprint('test MAE :{:.4f}|test RMSE :{:.4f}'.format(test_mae,test_rmse))","metadata":{"execution":{"iopub.status.busy":"2022-07-03T15:03:46.369627Z","iopub.execute_input":"2022-07-03T15:03:46.370168Z","iopub.status.idle":"2022-07-03T15:03:49.063739Z","shell.execute_reply.started":"2022-07-03T15:03:46.370136Z","shell.execute_reply":"2022-07-03T15:03:49.062489Z"},"trusted":true},"execution_count":null,"outputs":[]}]}